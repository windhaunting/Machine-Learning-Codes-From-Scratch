{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_layer_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpDL3uzWTwGi"
      },
      "source": [
        "#1st method:\n",
        "\n",
        "reference 1:\n",
        " \n",
        " https://towardsdatascience.com/a-guide-to-convolutional-neural-networks-from-scratch-f1e3bfc3e2de\n",
        "\n",
        "\n",
        "reference 2: \n",
        "\n",
        "https://datascience-enthusiast.com/DL/Convolution_model_Step_by_Stepv2.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ0pCw5rNTJL"
      },
      "source": [
        "class Convolutional_Layers_Scratch1(object):\n",
        "  def __init__(self):\n",
        "        pass\n",
        "    \n",
        "  def forward_conv_layer(self, X, w, b, stride, pad):\n",
        "    \"\"\"\n",
        "    X:  N x C x H x W, input data\n",
        "    w:  F x C x HH x WW, filter\n",
        "    b: F x 1 , bias\n",
        "\n",
        "    N: the number of input\n",
        "    C:  then number of channel\n",
        "    H:  the height of input image\n",
        "    W: the weight of input image\n",
        "\n",
        "    F: the number of the filter\n",
        "    HH: the height of the filter\n",
        "    WW: the width of the filter\n",
        "\n",
        "    out_H = (H - HH + 2P)/S + 1\n",
        "    \"\"\"\n",
        "\n",
        "    N, C, H, W = x.shape\n",
        "    F, _, HH, WW = w.shape\n",
        "\n",
        "    # get output shape\n",
        "    H_out = (H - HH + 2 * pad) // stride + 1\n",
        "    W_out = (W - WW + 2 * pad) // stride + 1\n",
        "    out = np.zeros((N, F, H_out, W_out))\n",
        "\n",
        "    # padding\n",
        "    pad_width = ((0, ), (0, ), (pad, ), (pad, ))\n",
        "    xpad = np.pad(x, pad_widths, 'constant')\n",
        "    Npad, Cpad, Hpad, Wpad = xpad.shape\n",
        "    \n",
        "    # calculate convolution\n",
        "    for n in range(N):\n",
        "      for f in range(F):\n",
        "        for i in range(0, Hpad - (HH-1), stride):\n",
        "          for j in range(0, Wpad - (WW -1), stride):\n",
        "            prod = np.sum(np.multiply(w[f,...], xpad[n, :, i:i+HH, j:j+WW]))\n",
        "            out[n, f, int(i/stride), int(j/stride)] = prod + b[f]\n",
        "    cache = (x, w, b, stride, pad)\n",
        "    return out, cache\n",
        "\n",
        "\n",
        "  def max_pooling_layer(x, Hp, Wp, stride)\n",
        "    '''\n",
        "    x:  N x C x H x W,   input matrix\n",
        "    Hp: pooling height\n",
        "    Wp: pooling width\n",
        "    stride: stride\n",
        "    '''\n",
        "    N, C, H, W = x.x_shape\n",
        "    H1 = (H - Hp)//stride + 1\n",
        "    W1 = (W - Wp)//stride + 1\n",
        "    out = np.zeros(N, C, H1, W1)\n",
        "    \n",
        "    # Max pooling operation\n",
        "    for n in range(N):\n",
        "      for c in range(C):\n",
        "        for k in range(H1):\n",
        "          for l in range(W1):\n",
        "            out[n, c, k, l] = np.max(x[n, c, k*stride:k*stride+Hp, 1*stride:1+stride+Wp])\n",
        "    cache = (x, Hp, Wp, stride)\n",
        "\n",
        "\n",
        "def back_conv_layer(dout, cache):\n",
        "  '''\n",
        "  Input: dout--derivative of dL/out\n",
        "  output: dx, dw, db\n",
        "  '''\n",
        "  dx, dw, db = None, None, None\n",
        "  x, w, b, stride, pad = cache\n",
        "  N, C, H, W = x.x_shape\n",
        "  F, _, HH, WW = w.x_shape\n",
        "  _, _, Hout, Wout = dout.shape\n",
        "  \n",
        "  # padding\n",
        "  pad_widths = ((0, ), (0, ), (pad, ), (pad, ))\n",
        "  xpad = np.pad(x, pad_widths, 'constant')\n",
        "  dxpad = np.zeros_like(xpad)\n",
        "  dw = np.zeros_like(w)\n",
        "  db = np.zeros_like(b)\n",
        "\n",
        "  # get dw, dxpad with convolution\n",
        "  for n in range(N):\n",
        "    for f in range(F):\n",
        "      # db at index f: summing dout for a given filter f\n",
        "      db[f] += np.sum(dout[n, f])\n",
        "    for i in range(Hout):\n",
        "      for j in range(Wout):\n",
        "        dw[f] += xpad[n, :, i*stride:i*stride+HH, j*stride:j*stride+WW] * dout[n, f, i, j]\n",
        "        dxpad[n, :, i*stride:i*stride+HH, j*stride:j*stride+WW] += w[f] * dout[n, f, i, j]\n",
        "  dx = dxpad[:, :, pad:pad+H, pad:pad+W]\n",
        "  return dx, dw, db\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwl1ZrI0NNz2"
      },
      "source": [
        "\n",
        "**Convolutional layers from scratch**\n",
        "\n",
        "# 2nd method:\n",
        "\n",
        "# reference: \n",
        "https://wiseodd.github.io/techblog/2016/07/16/convnet-conv-layer/\n",
        "\n",
        "and \n",
        "\n",
        "https://github.com/huyouare/CS231n/blob/master/assignment2/cs231n/im2col.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqfNHp2TxtQ"
      },
      "source": [
        "class Convolutional_Layers_Scratch1(object):\n",
        "  def __init__(self):\n",
        "        pass\n",
        "    \n",
        "  def forward_cnn(self, X, F, b, stride=1, padding=1):\n",
        "    \"\"\"\n",
        "    X:  D x C x H x W\n",
        "    F:  NF x C x HF x WF\n",
        "    b: F x 1\n",
        "\n",
        "    D: the number of input\n",
        "    C:  then number of channel\n",
        "    H:  the height of input image\n",
        "    W: the weight of input image\n",
        "\n",
        "    NF: the number of the filter\n",
        "    HF: the height of the filter\n",
        "    WF: the width of the filter\n",
        "\n",
        "    out_H = (H - HF + 2P)/S + 1\n",
        "    \"\"\"\n",
        "\n",
        "    cache = F, b, stride, padding\n",
        "    n_filter, d_filter, h_filter, w_filter = F.shape\n",
        "    n_x, d_x, h_x, w_x = X.shape\n",
        "    \n",
        "    # make sure is integer\n",
        "    assert (h_x - h_filter + 2*padding) % stride == 0\n",
        "    assert (w_x - w_filter + 2*padding) % stride == 0\n",
        "    h_out = (h_x - h_filter + 2*padding)/stride + 1\n",
        "    w_out = (w_x - w_filter + 2*padding)/stride + 1\n",
        "\n",
        "    h_out, w_out = int(h_out), int(w_out)\n",
        "\n",
        "    X_col = self.im2col_indices(X, h_filter, w_filter, padding=padding, stride=stride)\n",
        "    W_col = F.reshape(n_filter, -1)\n",
        "    \n",
        "    out = W_col @ X_col + b\n",
        "    out = out.reshape(n_filter, h_out, w_out, n_x)\n",
        "    out = out.transpose(3, 0, 1, 2)\n",
        "\n",
        "    cache = (X, F, b, stride, padding, X_col)\n",
        "\n",
        "    return out, cache\n",
        "    \n",
        "  def conv_backward(dout, cache):\n",
        "    X, F, b, stride, padding, X_col = cache\n",
        "    n_filter, d_filter, h_filter, w_filter = F.shape\n",
        "\n",
        "    db = np.sum(dout, axis=(0, 2, 3))              # dout -> db\n",
        "    db = db.reshape(n_filter, -1)\n",
        "\n",
        "    dout_reshaped = dout.transpose(1, 2, 3, 0).reshape(n_filter, -1)\n",
        "    dF = dout_reshaped @ X_col.T\n",
        "    dF = dF.reshape(F.shape)\n",
        "\n",
        "    F_reshape = F.reshape(n_filter, -1)\n",
        "    dX_col = F_reshape.T @ dout_reshaped\n",
        "    dX = col2im_indices(dX_col, X.shape, h_filter, w_filter, padding=padding, stride=stride)\n",
        "\n",
        "\n",
        "    return dX, dF, db\n",
        "\n",
        "\n",
        "  def im2col_indices(self,x, field_height, field_width, padding=1, stride=1):\n",
        "      \"\"\" An implementation of im2col based on some fancy indexing \"\"\"\n",
        "      # Zero-pad the input\n",
        "      p = padding\n",
        "      x_padded = np.pad(x, ((0, 0), (0, 0), (p, p), (p, p)), mode='constant')\n",
        "\n",
        "      k, i, j = get_im2col_indices(x.shape, field_height, field_width, padding,\n",
        "                                  stride)\n",
        "\n",
        "      cols = x_padded[:, k, i, j]\n",
        "      C = x.shape[1]\n",
        "      cols = cols.transpose(1, 2, 0).reshape(field_height * field_width * C, -1)\n",
        "      return cols\n",
        "\n",
        "  def get_im2col_indices(self, x_shape, field_height, field_width, padding=1, stride=1):\n",
        "      # First figure out what the size of the output should be\n",
        "      N, C, H, W = x_shape\n",
        "      assert (H + 2 * padding - field_height) % stride == 0\n",
        "      assert (W + 2 * padding - field_height) % stride == 0\n",
        "      out_height = (H + 2 * padding - field_height) / stride + 1\n",
        "      out_width = (W + 2 * padding - field_width) / stride + 1\n",
        "\n",
        "      i0 = np.repeat(np.arange(field_height), field_width)\n",
        "      i0 = np.tile(i0, C)\n",
        "      i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
        "      j0 = np.tile(np.arange(field_width), field_height * C)\n",
        "      j1 = stride * np.tile(np.arange(out_width), out_height)\n",
        "      i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
        "      j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
        "\n",
        "      k = np.repeat(np.arange(C), field_height * field_width).reshape(-1, 1)\n",
        "\n",
        "      return (k, i, j)\n",
        "\n",
        "\n",
        "  def col2im_indices(self, cols, x_shape, field_height=3, field_width=3, padding=1,\n",
        "                    stride=1):\n",
        "    \"\"\" An implementation of col2im based on fancy indexing and np.add.at \"\"\"\n",
        "    N, C, H, W = x_shape\n",
        "    H_padded, W_padded = H + 2 * padding, W + 2 * padding\n",
        "    x_padded = np.zeros((N, C, H_padded, W_padded), dtype=cols.dtype)\n",
        "    k, i, j = get_im2col_indices(x_shape, field_height, field_width, padding,\n",
        "                                stride)\n",
        "    cols_reshaped = cols.reshape(C * field_height * field_width, -1, N)\n",
        "    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\n",
        "    np.add.at(x_padded, (slice(None), k, i, j), cols_reshaped)\n",
        "    if padding == 0:\n",
        "      return x_padded\n",
        "    return x_padded[:, :, padding:-padding, padding:-padding]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZUgLi9vUDeC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwDL9mIYuOK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfQgYwEGMey5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsI2gUJFM9jH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLhL9E60oZym"
      },
      "source": [
        "## 3rd method\n",
        "Using bult-in function from Tesnorflow or Pytorch, etc."
      ]
    }
  ]
}
